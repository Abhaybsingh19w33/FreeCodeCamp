{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_o2L3Io9t4c"
   },
   "source": [
    "# Deep Computer Vision\n",
    "\n",
    "In this guide we will learn how to peform *image classification and object detection/recognition* using deep computer vision with something called a **convolutional neural network**.\n",
    "\n",
    "The goal of our convolutional neural networks will be to classify and detect images or specific objects from within the image. We will be using image data as our features and a label for those images as our label or output.\n",
    "\n",
    "We already know how neural networks work so we can skip through the basics and move right into explaining the following concepts.\n",
    "- Image Data\n",
    "- Convolutional Layer\n",
    "- Pooling Layer\n",
    "- CNN Architectures\n",
    "\n",
    "The major differences we are about to see in these types of neural networks are the layers that make them up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdqlqfhLCHZl"
   },
   "source": [
    "## Image Data\n",
    "So far, we have dealt with pretty straight forward data that has 1 or 2 dimensions. Now we are about to deal with image data that is usually made up of 3 dimensions. These 3 dimensions are as follows:\n",
    "- image height\n",
    "- image width\n",
    "- color channels\n",
    "\n",
    "The only item in the list above you may not understand is **color channels**. The number of color channels represents the depth of an image and coorelates to the colors used in it. For example, an image with three channels is likely made up of rgb (red, green, blue) pixels. So, for each pixel we have three numeric values in the range 0-255 that define its color. For an image of color depth 1 we would likely have a greyscale image with one value defining each pixel, again in the range of 0-255.\n",
    "\n",
    "![alt text](http://xrds.acm.org/blog/wp-content/uploads/2016/06/Figure1.png)\n",
    "\n",
    "Keep this in mind as we discuss how our network works and the input/output of each layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mqznmTh--v2"
   },
   "source": [
    "## Convolutional Neural Network\n",
    "**Note:** I will use the term *convnet* and convolutional neural network interchangably.\n",
    "\n",
    "Each convolutional neural network is made up of one or many convolutional layers. These layers are different than the *dense* layers we have seen previously. Their goal is to find patterns from within images that can be used to classify the image or parts of it. But this may sound familiar to what our densly connected neural network in the previous section was doing, well that's becasue it is. \n",
    "\n",
    "The fundemental difference between a dense layer and a convolutional layer is that dense layers detect patterns globally while convolutional layers detect patterns locally. When we have a densly connected layer each node in that layer sees all the data from the previous layer. This means that this layer is looking at all the information and is only capable of analyzing the data in a global capacity. Our convolutional layer however will not be densly connected, this means it can detect local patterns using part of the input data to that layer.\n",
    "\n",
    "*Let's have a look at how a densly connected layer would look at an image vs how a convolutional layer would.*\n",
    "\n",
    "This is our image; the goal of our network will be to determine whether this image is a cat or not.\n",
    "![alt text](https://img.webmd.com/dtmcms/live/webmd/consumer_assets/site_images/article_thumbnails/reference_guide/cat_weight_ref_guide/1800x1200_cat_weight_ref_guide.jpg)\n",
    "\n",
    "**Dense Layer:** A dense layer will consider the ENTIRE image. It will look at all the pixels and use that information to generate some output.\n",
    "\n",
    "**Convolutional Layer:** The convolutional layer will look at specific parts of the image. In this example let's say it analyzes the highlighted parts below and detects patterns there.\n",
    "![alt text](https://drive.google.com/uc?export=view&id=1M7v7S-b-zisFLI_G4ZY_RdUJQrGpJ3zt)\n",
    "\n",
    "Can you see why this might make these networks more useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIQvxFu_FB3h"
   },
   "source": [
    "### How They Work\n",
    "A dense neural network learns patterns that are present in one specific area of an image. This means if a pattern that the network knows is present in a different area of the image it will have to learn the pattern again in that new area to be able to detect it. \n",
    "\n",
    "*Let's use an example to better illustrate this.*\n",
    "\n",
    "We'll consider that we have a dense neural network that has learned what an eye looks like from a sample of dog images.\n",
    "\n",
    "![alt text](https://drive.google.com/uc?export=view&id=16FJKkVS_lZToQOCOOy6ohUpspWgtoQ-c)\n",
    "\n",
    "Let's say it's determined that an image is likely to be a dog if an eye is present in the boxed off locations of the image above.\n",
    "\n",
    "Now let's flip the image.\n",
    "![alt text](https://drive.google.com/uc?export=view&id=1V7Dh7BiaOvMq5Pm_jzpQfJTZcpPNmN0W)\n",
    "\n",
    "Since our densly connected network has only recognized patterns globally it will look where it thinks the eyes should be present. Clearly it does not find them there and therefore would likely determine this image is not a dog. Even though the pattern of the eyes is present, it's just in a different location.\n",
    "\n",
    "Since convolutional layers learn and detect patterns from different areas of the image, they don't have problems with the example we just illustrated. They know what an eye looks like and by analyzing different parts of the image can find where it is present. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20J29gz-NroA"
   },
   "source": [
    "### Multiple Convolutional Layers\n",
    "In our models it is quite common to have more than one convolutional layer. Even the basic example we will use in this guide will be made up of 3 convolutional layers. These layers work together by increasing complexity and abstraction at each subsequent layer. The first layer might be responsible for picking up edges and short lines, while the second layer will take as input these lines and start forming shapes or polygons. Finally, the last layer might take these shapes and determine which combiantions make up a specific image.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ii-a9rXzRwNi"
   },
   "source": [
    "## Feature Maps\n",
    "You may see me use the term *feature map* throughout this tutorial. This term simply stands for a 3D tensor with two spacial axes (width and height) and one depth axis. Our convolutional layers take feature maps as their input and return a new feature map that reprsents the prescence of spcific filters from the previous feature map. These are what we call *response maps*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OScABB-ScXHx"
   },
   "source": [
    "## Layer Parameters\n",
    "A convolutional layer is defined by two key parameters.\n",
    "\n",
    "#### **Filters**\n",
    "A filter is a m x n pattern of pixels that we are looking for in an image. The number of filters in a convolutional layer reprsents how many patterns each layer is looking for and what the depth of our response map will be. If we are looking for 32 different patterns/filters than our output feature map (aka the response map) will have a depth of 32. Each one of the 32 layers of depth will be a matrix of some size containing values indicating if the filter was present at that location or not.\n",
    "\n",
    "Here's a great illustration from the book \"Deep Learning with Python\" by Francois Chollet (pg 124).\n",
    "![alt text](https://drive.google.com/uc?export=view&id=1HcLvvLKvLCCGuGZPMvKYz437FbbCC2eB)\n",
    "\n",
    "#### **Sample Size**\n",
    "This isn't really the best term to describe this, but each convolutional layer is going to examine n x m blocks of pixels in each image. Typically, we'll consider 3x3 or 5x5 blocks. In the example above we use a 3x3 \"sample size\". This size will be the same as the size of our filter. \n",
    "\n",
    "Our layers work by sliding these filters of n x m pixels over every possible position in our image and populating a new feature map/response map indicating whether the filter is present at each location. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vnzqr8Dzjchd"
   },
   "source": [
    "## Borders and Padding\n",
    "The more mathematical of you may have realized that if we slide a filter of let's say size 3x3 over our image well consider less positions for our filter than pixels in our input. Look at the example below. \n",
    "\n",
    "*Image from \"Deep Learning with Python\" by Francois Chollet (pg 126).*\n",
    "![alt text](https://drive.google.com/uc?export=view&id=1OEfXrV16NBjwAafgBfYYcWOyBCHqaZ5M)\n",
    "\n",
    "This means our response map will have a slightly smaller width and height than our original image. This is fine but sometimes we want our response map to have the same dimensions. We can accomplish this by using something called *padding*.\n",
    "\n",
    "**Padding** is simply the addition of the appropriate number of rows and/or columns to your input data such that each pixel can be centered by the filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDwH2eOMmt_N"
   },
   "source": [
    "## Strides\n",
    "In the previous sections we assumed that the filters would be slid continously through the image such that it covered every possible position. This is common but sometimes we introduce the idea of a **stride** to our convolutional layer. The stride size reprsents how many rows/cols we will move the filter each time. These are not used very frequently so we'll move on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCsVC-4UnfC8"
   },
   "source": [
    "## Pooling\n",
    "You may recall that our convnets are made up of a stack of convolution and pooling layers.\n",
    "\n",
    "The idea behind a pooling layer is to downsample our feature maps and reduce their dimensions. They work in a similar way to convolutional layers where they extract windows from the feature map and return a response map of the max, min or average values of each channel. Pooling is usually done using windows of size 2x2 and a stride of 2. This will reduce the size of the feature map by a factor of two and return a response map that is 2x smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qo85O0LsxbB"
   },
   "source": [
    "## A More Detailed Look\n",
    "Please refer to the video to learn how all of this happens at the lower level! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xqLsm2XzNQSE"
   },
   "source": [
    "## Creating a Convnet\n",
    "\n",
    "Now it is time to create our first convnet! This example is for the purpose of getting familiar with CNN architectures, we will talk about how to improves its performance later.\n",
    "\n",
    "*This tutorial is based on the following guide from the TensorFlow documentation: https://www.tensorflow.org/tutorials/images/cnn*\n",
    "\n",
    "### Dataset\n",
    "The problem we will consider here is classifying 10 different everyday objects. The dataset we will use is built into tensorflow and called the [**CIFAR Image Dataset.**](https://www.cs.toronto.edu/~kriz/cifar.html) It contains 60,000 32x32 color images with 6000 images of each class. \n",
    "\n",
    "The labels in this dataset are the following:\n",
    "- Airplane\n",
    "- Automobile\n",
    "- Bird\n",
    "- Cat\n",
    "- Deer\n",
    "- Dog\n",
    "- Frog\n",
    "- Horse\n",
    "- Ship\n",
    "- Truck\n",
    "\n",
    "We'll load the dataset and have a look at some of the images below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "bnIbwiK7Ohv2"
   },
   "outputs": [],
   "source": [
    "# %tensorflow_version 2.x  # this line is not required unless you are in a notebook\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "49wbEaM1PCCR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  LOAD AND SPLIT DATASET\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Bp0yAAcuPHFN"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's look at a one image\n",
    "IMG_INDEX = 7  # change this to look at other images\n",
    "\n",
    "plt.imshow(train_images[IMG_INDEX] ,cmap=plt.cm.binary)\n",
    "plt.xlabel(class_names[train_labels[IMG_INDEX][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPqeddhcPwpc"
   },
   "source": [
    "## CNN Architecture\n",
    "A common architecture for a CNN is a stack of Conv2D and MaxPooling2D layers followed by a few denesly connected layers. To idea is that the stack of convolutional and maxPooling layers extract the features from the image. Then these features are flattened and fed to densly connected layers that determine the class of an image based on the presence of features.\n",
    "\n",
    "We will start by building the **Convolutional Base**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ibuJZqAXQrWJ"
   },
   "outputs": [],
   "source": [
    "# this will extract the features from input data\n",
    "\n",
    "model = models.Sequential()\n",
    "# first parameter 32 is number of filters to be created\n",
    "# second parameter (3,3) is the size of those filters\n",
    "# third parameter is activation function relu\n",
    "# forth parameter input_shape provides the input shape, here is 32,32,3 shape of an image\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "# poolong will shrink the layers by factor of 2,2 and stride of 2\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tybTBoi_Qtxl"
   },
   "source": [
    "**Layer 1**\n",
    "\n",
    "The input shape of our data will be 32, 32, 3 and we will process 32 filters of size 3x3 over our input data. We will also apply the activation function relu to the output of each convolution operation.\n",
    "\n",
    "**Layer 2**\n",
    "\n",
    "This layer will perform the max pooling operation using 2x2 samples and a stride of 2.\n",
    "\n",
    "**Other Layers**\n",
    "\n",
    "The next set of layers do very similar things but take as input the feature map from the previous layer. They also increase the frequency of filters from 32 to 64. We can do this as our data shrinks in spacial dimensions as it passed through the layers, meaning we can afford (computationally) to add more depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "_QahwuduSEDG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 15, 15, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,320\n",
      "Trainable params: 56,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()  # let's have a look at our model so far\n",
    "# here cov2d after sampling the images we get 30,30\n",
    "# after maxpooling we get 15,15\n",
    "# after convolution we get sampling 13,13\n",
    "# again after peprforming maxpooling 6,6\n",
    "# aftre sampling we get 4,4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXw-sreaSzTW"
   },
   "source": [
    "After looking at the summary you should notice that the depth of our image increases but the spacial dimensions reduce drastically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjtADcfmSI9q"
   },
   "source": [
    "## Adding Dense Layers\n",
    "So far, we have just completed the **convolutional base**. Now we need to take these extracted features and add a way to classify them. This is why we add the following layers to our model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "A9TMZH_oSULo"
   },
   "outputs": [],
   "source": [
    "# this will be the classsififer\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "fEzHX-7ESeCl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 15, 15, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                65600     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,570\n",
      "Trainable params: 122,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxfqtdDbSf4W"
   },
   "source": [
    "We can see that the flatten layer changes the shape of our data so that we can feed it to the 64-node dense layer, follwed by the final output layer of 10 neurons (one for each class).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdPxFvHdTLRK"
   },
   "source": [
    "## Training\n",
    "Now we will train and compile the model using the recommended hyper paramaters from tensorflow.\n",
    "\n",
    "*Note: This will take much longer than previous models!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "5loIug93TW1E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 41s 23ms/step - loss: 1.5246 - accuracy: 0.4442 - val_loss: 1.2415 - val_accuracy: 0.5560\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 1.1525 - accuracy: 0.5919 - val_loss: 1.0614 - val_accuracy: 0.6284\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 1.0063 - accuracy: 0.6470 - val_loss: 0.9893 - val_accuracy: 0.6617\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 38s 24ms/step - loss: 0.9121 - accuracy: 0.6802 - val_loss: 0.9128 - val_accuracy: 0.6838\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.8336 - accuracy: 0.7073 - val_loss: 1.0101 - val_accuracy: 0.6536\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 35s 23ms/step - loss: 0.7768 - accuracy: 0.7283 - val_loss: 0.9012 - val_accuracy: 0.6900\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.7263 - accuracy: 0.7436 - val_loss: 0.8911 - val_accuracy: 0.6949\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.6809 - accuracy: 0.7601 - val_loss: 0.8911 - val_accuracy: 0.6992\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 36s 23ms/step - loss: 0.6391 - accuracy: 0.7771 - val_loss: 0.8604 - val_accuracy: 0.7144\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 36s 23ms/step - loss: 0.6010 - accuracy: 0.7883 - val_loss: 0.8586 - val_accuracy: 0.7117\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=10, \n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkdRKQnETgLv"
   },
   "source": [
    "## Evaluating the Model\n",
    "We can determine how well the model performed by looking at it's performance on the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "6I2vJFiiTkQE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 2s - loss: 0.8586 - accuracy: 0.7117 - 2s/epoch - 5ms/step\n",
      "0.7117000222206116\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lKwDlvvUbIm"
   },
   "source": [
    "You should be getting an accuracy of about 70%. This isn't bad for a simple model like this, but we'll dive into some better approaches for computer vision below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cstpZFVaY7YH"
   },
   "source": [
    "## Working with Small Datasets\n",
    "In the situation where you don't have millions of images it is difficult to train a CNN from scratch that performs very well. This is why we will learn about a few techniques we can use to train CNN's on small datasets of just a few thousand images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8D4iWJ17ZRt_"
   },
   "source": [
    "### Data Augmentation\n",
    "To avoid overfitting and create a larger dataset from a smaller one we can use a technique called data augmentation. This is simply performing random transofrmations on our images so that our model can generalize better. These transformations can be things like compressions, rotations, stretches and even color changes. \n",
    "\n",
    "Fortunately, keras can help us do this. Look at the code below to an example of data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "_sOet0hQZ-gR"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAb6UlEQVR4nO2da2yk53Xf/2euvC/J5S6X2ov24pVsxXZkYaEKVZM4dWuohgHbDWzEQAJ9MLL5EAMxkKJVXaB2v7lF7cAfCgPrWohSuL6gtmGhMJqoalIjqaF4rUiy5JWti1fS7lJ7Jbm8zXAupx9mBKyU53/IHZLDlZ//DyBIPofP+555+J55Z57/nHPM3SGE+NWnsNMOCCH6g4JdiExQsAuRCQp2ITJBwS5EJijYhciE0mYmm9kDAL4MoAjgv7r7F6K/HxkZ8d2Tk0lbpAC22q3keLPZ5L4V+PNYocAfdiGYx+fYTc8BED/oaFroS5HM4bMi+ZUdDwBKRW5rt9P/m3a7Tef0ihlff0Pa1gr8iNeDXx+lIr+uypVKT8e8WS5cOI/5uWvJB91zsJtZEcB/AfDPAZwD8GMze9Tdf8bm7J6cxL/9N/86aWs00gENAHPXF5LjV65doXPKA8PUNjS8m9pGR4aojV1Tg4ODdE504XgreLICvxibbX7M6vBoek6Lz2mSwASAoSG+HhNju6htdfFqcnxtbZXO6ZVi8ORdLJaT48vLK3TO2lqD2gYH+XU1Ocmvq/0HDlJbtMYMdln93if/JZ2zmaeUewG86O4vu/sagG8C+MgmjieE2EY2E+z7Abx2w+/numNCiFuQzQR76kXtP3hxYWYnzey0mZ1eWlraxOmEEJthM8F+DsCNb0QOALjw1j9y91PufsLdT4yMjGzidEKIzbCZYP8xgONmdsTMKgB+F8CjW+OWEGKr6Xk33t2bZvZpAH+BjvT2sLs/F80xM5TK6d3RSE8aGUq/Ilha5m8L1ho1bqsvU1u9QvwDUK2kl6vR4Lu3ZfZ4ASCQXDzYcS8atzXq6d3ucpXv+LadS2i1Gl/HlTKXk0bH0jvT166co3MKFsh8Jb6OtVqd2ubn09fI4CBfj6mpCWqLdtUnJtKy8nqwnfVQyeGT6JxN6ezu/gMAP9jMMYQQ/UGfoBMiExTsQmSCgl2ITFCwC5EJCnYhMmFTu/E3S6FYxMjoWNI2fy2dOAFwyWtiF5c6LlzkEk9jjUt2tRpPaqkQGS2S3kolvsQWZJR5kJUVZXm1SSagl3mySzGQAJst7sdqIMtViFQ2ODjOj7fC/y9zc9eprRxIgOPj6Wtk//4DdM70vhlqi4iSGHuS0cJzpeeEGZE3fRYhxNsSBbsQmaBgFyITFOxCZIKCXYhM6O9ufKGASnUgaasGpZ3qK+nkjsGBKp0zNspLJi2t8ESYtTrfEV4lu/FDg9yPtbU1aqtW+bx4pz5IkimkbY1g57w6zFOPg1OhHjy2uYX0OpaC+8tajR9vZCRdbgsA9u7dR20scaUY1M/r5656NG+rW7Ppzi5EJijYhcgEBbsQmaBgFyITFOxCZIKCXYhM6Kv0BhiMtMhhCTIAUF9NS28DQb248TFeRyyqXddsBPXp6mnZsBL4EaUmtFq8C04sDQXP0USuiTrMDJBEIwAYHeUdUM7Pvk5t12vpdbxt+jY6Z2b3UWrbP7OH2ga3sKMK0HuLqu2Q5RhRMhRDd3YhMkHBLkQmKNiFyAQFuxCZoGAXIhMU7EJkwqakNzM7C2ARQAtA091PRH/farewSDq5jgzxrLfh0XTG0/LiIp0TyXJR7bprC7wWXoNkxNWCGmgjw1wWijLiBoMswCgjjrXKmto9TucsLHK5sba6Qm3DgeQ1Pp6WPm8/xNsn7Rrl2XelIpeaeslS61Um22oJDehNRmNzoiNthc7+2+5+ZQuOI4TYRvQyXohM2GywO4C/NLOfmNnJrXBICLE9bPZl/P3ufsHM9gJ4zMyed/cf3vgH3SeBkwCwe/fUJk8nhOiVTd3Z3f1C9/slAN8DcG/ib065+wl3PzE6xksLCSG2l56D3cyGzWz0jZ8BfBDAs1vlmBBia9nMy/hpAN/rSgAlAP/d3f9XNKHVamF+YT5pi2ScIVIQMZKFoj44YyNc4lle4XJeo5Eu2livcz8qgSxXqXAJLcp6m5nh7YmqRHKs19KZgwBgwWKZ88y8Qwf2U9vuyfRbtlLwuArG/Wg2e8sQZGyHvNaLhNadmRwtFPjx6LkCH3oOdnd/GcCv9zpfCNFfJL0JkQkKdiEyQcEuRCYo2IXIBAW7EJnQ14KT7XYLtdXrSdv8Ai9sODme7ts2EvRzW5i7Rm1MngLijLjZS7PJcZYNBwBrVS4pTk8foLYoWy4qiNhsEZvx5/VJIpMBwC6SvQYAxSJfR6PniyQvagrlsKhwZ+9yWC/H60EqQyyxbSW6swuRCQp2ITJBwS5EJijYhcgEBbsQmdDX3Xhvt+nO9fXFBTqPJclUBnidtupAulUTANRX0wktADAU1H4bHUmn6JaC3f2ZoG3RWqNBbVeu8lp4g4P8sU1OptWEqSnuR5SsUyrxS6Td5jvkvbZQ6gUPzmUkSabXXXquMvRvV71XdGcXIhMU7EJkgoJdiExQsAuRCQp2ITJBwS5EJvRVejO0UWylWx6xBBkAmFtIS2/79u6lc4ZHx6itXuPS2+AAl6EO7j+UHL82f5nOWV6aozYr8uSfaqVKbXv3TlPb5ERaeiuVoqQVLhndKvJaSKB4sQSaQoHf56L12OrEmn6iO7sQmaBgFyITFOxCZIKCXYhMULALkQkKdiEyYV3pzcweBvBhAJfc/d3dsUkA3wJwGMBZAJ9wd64xvYE7vFlPmwq8PdHKclqWW1rm0tVAhT+0Qom3C6qtBm2SLH1MAz/eyhJvJ3Xnrx2ntr3TvLVSNchEKxFJqbeGRr23QuqFrW6fBHD/3w7yWm9rz+ds5M7+ZwAeeMvYQwAed/fjAB7v/i6EuIVZN9i7/dbfWqr1IwAe6f78CICPbq1bQoitptf37NPuPgsA3e/8o2xCiFuCbd+gM7OTZnbazE4vr/D3w0KI7aXXYL9oZjMA0P1+if2hu59y9xPufmJ4iJd8EkJsL70G+6MAHuz+/CCA72+NO0KI7WIj0ts3ALwfwJSZnQPwOQBfAPBtM/sUgFcBfHwjJ2t7G2v19Ev5gSAra62Wlq9q9d10TmMtnV0HAKs1bru+wAtfjo+NJ8f3TM/QOTOHbqe20V3c/0qQ9dZc41l73ko/fxeCQolvBxlqq4ky9oqkSOVm6EVGizLzmM0CGXLdYHf3TxLTB9abK4S4ddAn6ITIBAW7EJmgYBciExTsQmSCgl2ITOhrwcl227GykpaNKiVe6HG4Mp4cLzmXT1bXmtRWD2yju9IFGwHg9mPpLLXRCS6hDY7torZ2s0VtzQb/tOFzzz5FbWOj48nxo0fupHOiTKlIotpqya5XmS+StXqR0aLjRT5G83qR0SLY/yUS+HRnFyITFOxCZIKCXYhMULALkQkKdiEyQcEuRCb0VXqDO7zVSJraQSYX2mkZamnlCp2y1uZZdAcPH6W2qd286M4YyXpDIJ20AplvYWGe2paXePbdpdfPUdtLLzyfHPcWF2Xecfyd1BZxq0hv6MGPSFJstbgkWgqKfUYyXy+SXbPJrx3mYyj/UYsQ4lcKBbsQmaBgFyITFOxCZIKCXYhM6OtuvLuj1kjvgpabQcJFfSk5vv8Ar+82te8ItU1OTFNbtcor4LK6dtHObqkQtKFyvnv7ysuvUJu1+W4x6ul6fQtXaQFgtI68g9qKwe5zL7vx0W5xbONr7IEfbUuvcZiYQi0x0XpEO+vMFvrYQ4KP7uxCZIKCXYhMULALkQkKdiEyQcEuRCYo2IXIhI20f3oYwIcBXHL3d3fHPg/gDwBc7v7ZZ939B+uerVBEYWA8adp76Bidduz4u5LjI2O8XtzI6BS1RVJZvRYk5BAiyaUdJFVE88YnJqjt6pWz1LaylJbe5i6fp3PqqyvUNjg6Rm3NRjqpCQCWl5eT4wXj8truCV6vr9moUxvKQassssbR2hcD21qDtw5bC1qORVIZkzejFmYNsvYeXNsbubP/GYAHEuN/6u53d7/WD3QhxI6ybrC7+w8BXOuDL0KIbWQz79k/bWbPmNnDZsZfcwohbgl6DfavADgG4G4AswC+yP7QzE6a2WkzO726evPvh4UQW0NPwe7uF9295Z0PLH8VwL3B355y9xPufmJwcKBXP4UQm6SnYDezmRt+/RiAZ7fGHSHEdrER6e0bAN4PYMrMzgH4HID3m9nd6HSbOQvgDzdysuGRXbjvNz6YtE1P30bnjYymJZkgSQrNJpeFouyqXoiOZiX+fFoZ5hl2i3UuNc0vpmUtAHjx7Nnk+EqNZ13tPZCuWwcAx9/5HmqrVHjLrmtXLyfHV65fpXNeWOH7wJXqMLWVhrhkN3MoXW9wLGjL1WoH7Z+Cf3YowfYg90ZzGNG1uG6wu/snE8Nfu2kvhBA7ij5BJ0QmKNiFyAQFuxCZoGAXIhMU7EJkQl8LTlarVdx+5I6krVjgWUHtVlqCiGSGrZbXAAAFUkQxau0THK5c4dlad7/3fdS2a5Cv1cJcWvK6usBlrcf+919Q29X5dBYdAPzGb/0WtR07ejw5vrq6h865dOkCta0s88w89FB8McpeKwX/z0Jwf4yktyiDjbVyqlb59TEwkP6AWtSCSnd2ITJBwS5EJijYhcgEBbsQmaBgFyITFOxCZEJfpTcAMKTliSjDhwsanKhPVjsQxCKprJdSflE/t0JwsqGBIWobHR6ltuGhdHaYBelatRqXhV6/yAtVvnb+NWo7cvTO5PhQlffZmxkep7ZWkMUYyU1Orp5Skf/PilFmW3A1hgUng+txeJj9z3q58jm6swuRCQp2ITJBwS5EJijYhcgEBbsQmdD33fheaJOkFgt2OJ0krXSOF52L2wqW3vUtgu8Gl4Kd4sWFOWoz8N3nS5cuUtv81fnk+IFDe+mcY3ekd84B4MCBdOstAJjaf4ja2ky7cN4OK6obiGCNYeVgVtqPQlDerdXmPkZyTbR7XiItngCetBUdr5dEL93ZhcgEBbsQmaBgFyITFOxCZIKCXYhMULALkQkbaf90EMCfA9iHTi7IKXf/splNAvgWgMPotID6hLtzLQkAPJAMotY5NPkgarfDpYligT/sUpToUFtNji8sXadzzv7yJWp79RVue+GFM9RWr/F6bO21tI8ry7zd0XDQPum2gwf4uQI5rLWWbl81t3CJzllb449rcmqG2soW3LOIxBYlz7SavFVWJIdFyS4RTVKDLjpai7jhgTa4Ee+aAP7E3d8F4D4Af2RmdwF4CMDj7n4cwOPd34UQtyjrBru7z7r7k92fFwGcAbAfwEcAPNL9s0cAfHSbfBRCbAE39brDzA4DeB+AJwBMu/ss0HlCAMA/oiWE2HE2HOxmNgLgOwA+4+78Teo/nHfSzE6b2em5+fgtvRBi+9hQsJtZGZ1A/7q7f7c7fNHMZrr2GQDJnRd3P+XuJ9z9xMT4xFb4LITogXWD3Trbj18DcMbdv3SD6VEAD3Z/fhDA97fePSHEVrGRrLf7Afw+gJ+a2VPdsc8C+AKAb5vZpwC8CuDj6x3IrfOVIqwLRySNqK5atcQzoS7O8qyxy5dep7annnwiOf7qay/TOZde51LT/BxvyVQICqENDVaobe9Uur1So8GPNzg4Tm1EQQMAtILMPF+rJccXrqbbUwFA09NzAGDX+Di1Fcq8Xh+TbVnLpfWIpLew/VNwvnojvY6VoP1TqXzzCavrznD3vwEXtD9w02cUQuwI+gSdEJmgYBciExTsQmSCgl2ITFCwC5EJfS84yaS3qHyeIS1beItLP7985QVq+6vH/w+1/fjvfkRt7unzrS4v0znl0iC1DVQH+Lwyl3GGh7n0ViLzyhX+vF5f4+toQTHHcpFfPlZKZ5UdOHwHncN8B4BymctQ3uLr0W6nWzK1g6KSYUZc0KZspR7olFEnJyLZNZu8nVR9dSk53g4kPt3ZhcgEBbsQmaBgFyITFOxCZIKCXYhMULALkQl9l95YoloxKuRHbLMXeYbat775CLWdffnFmz4XABRJr7exkTE6p1TgstDAIJeTWi0uu1QKXBqqsqKHLS4LlQqB8Bn0ZisFhR5LJfK4y3w9IlkrUFlDqcyJ/268qGQruAc2Ah+joqnOKl8CQCvty+Iil3Th6eNFkqLu7EJkgoJdiExQsAuRCQp2ITJBwS5EJvR1N95gKJAd3ALZ6QaAdjO9FXv2pV/SORfPn6e2SrB7OzTA65mVSd0vY9k9AMrFIJGkzG3NFv/XeJvvJBeIKxbsqluwM10qRTXX+A6zkf9n1CLJmPMAGmvcRw9afdVq6WunVYgeM/ex1eKPuVFPt94C4qSWlaV0UkvU5mugmlY12oF/urMLkQkKdiEyQcEuRCYo2IXIBAW7EJmgYBciE9aV3szsIIA/B7APQBvAKXf/spl9HsAfAHijn89n3f0H6x2PJ5pwyaBSSieMjI+N0zmjI0FLoAZPQBkc5DXjhofSNeOqpaAWmwdSU1CYbO76PLW1gwQU5ksxmNMi7YcAoBDIa1FduCKpT9cOEklqgdR05Rpvo7UwzxNGxgZHkuMTU5N0Tr3OZbmllQVqu77AuxS3m/yYQyQhqhxIxEzajGrdbURnbwL4E3d/0sxGAfzEzB7r2v7U3f/zBo4hhNhhNtLrbRbAbPfnRTM7A2D/djsmhNhabuo9u5kdBvA+AG+0M/20mT1jZg+bmZqvC3ELs+FgN7MRAN8B8Bl3vw7gKwCOAbgbnTv/F8m8k2Z22sxORy2KhRDby4aC3TqdAr4D4Ovu/l0AcPeL7t5y9zaArwK4NzXX3U+5+wl3PzE+wTdFhBDby7rBbp0O818DcMbdv3TD+MwNf/YxAM9uvXtCiK1iI7vx9wP4fQA/NbOnumOfBfBJM7sbnc5NZwH84UZO6J7OUIoyl9rFtO3g7UfpnA99+Heo7fkz/Hnp4usXqK1QTOsa47vS8g4ADA9xmxV41ttYbYraXnn1NWorV0aT49NTM8lxAHj6yaep7fA73kNtleowtTHawf+5EmQBlipBbcAizyi7OPuz5Pj5V3hNvun976I2C2TWAZIVCQCFwNZopjMSm0HZujYxkvACsLHd+L9BWr1bV1MXQtw66BN0QmSCgl2ITFCwC5EJCnYhMkHBLkQm9LXgpLujxWSGFi+IuFqrJccndu+hc+67/wPUtm//YWr70d/+X2qbv3ouOT4+yT8sdOwOLuNM33aI2grFdIYdAPziFy9T29kX0q2t6mTdAWB4iLdk+tlzf09td9z1XmqrlFj2YCBPBcUox4Z2U9uuQW5bGEzLeS/+nD+u64s8w+7wnXdS2+XzvOBkqx20NyOtskqFoB1WEC/0PDc9QwjxtkTBLkQmKNiFyAQFuxCZoGAXIhMU7EJkQt+ltzVS3DAqRFippKWJtQbPdkKRP4/dduAYtb3rrkVqe+JvX0+O7z1wkM45cvzd1FYdGqO2IimyCQD/eN8Rajv6jncmx0//v7+mc6an05lyAFAgGYcAsLx4mdpsNC2LlkvBuaw3WQ5Br73x3YeT47cf49Lmco0XsJy7doXa1oJ+bu02Lx7JqkRGvQBZ9miE7uxCZIKCXYhMULALkQkKdiEyQcEuRCYo2IXIhL5Kb2aGIulfNTDApRDWv4q2jQPQci7ltVu8t9nlc+msMQAwIvW1GkFlwKCoJIzLa62gR1y9wYslju3elRy/8z1cAiwF67hn7zS1hf3XFtI9Amb28V4iFvT7a7bTmY+difwBtIgEO76HZ0wun+M9537xs+epbWSUS6mjozwzz4l0GMnRFl38BN3ZhcgEBbsQmaBgFyITFOxCZIKCXYhMWHc33swGAPwQQLX79//D3T9nZpMAvgXgMDrtnz7h7nPrHAvlSnp3uofNxTAZwFt8J3OAJNYAwJ5gl/bCq+nd85de5DXh7vlHv01tzUAxMOc1xlrtJrW1W2nbwvXrdM6+PfuorTrAd5jHxqkJFy/PJscvzPLWVdUqTxaprXH/R0d4DcBWM31hzc6ep3M8WN/xca4mXF9coLZKhatNA4PpNW40uR9Vcg1Hu/QbubPXAfxTd/91dNozP2Bm9wF4CMDj7n4cwOPd34UQtyjrBrt3WOr+Wu5+OYCPAHikO/4IgI9uh4NCiK1ho/3Zi90OrpcAPObuTwCYdvdZAOh+37ttXgohNs2Ggt3dW+5+N4ADAO41M/5xrLdgZifN7LSZnZ6fS3+qSgix/dzUbry7zwP4awAPALhoZjMA0P2e/Oyku59y9xPufmJ8gm+kCCG2l3WD3cz2mNl49+dBAP8MwPMAHgXwYPfPHgTw/W3yUQixBWwkEWYGwCNmVkTnyeHb7v4/zexHAL5tZp8C8CqAj2/khL1IbE0iQdRqvObX/HVeS254ZITapg8dpbbjpDbZYnCun5/hiRPvvucEtbXaXHrzQJJZJr7U6jz5Z3RinJ+ryC+RwUDymqkSiTVIdgm6HWH5Il/jUpG1mgIW5tJqcLC8iMq7DQwMUdvy8hK1ra5yW7mclnStwCVi1v4pkqPXDXZ3fwbA+xLjVwHwhmpCiFsKfYJOiExQsAuRCQp2ITJBwS5EJijYhcgE66WNTM8nM7sM4JXur1MAeC+d/iE/3oz8eDNvNz9ud/dk6mZfg/1NJzY77e5caJYf8kN+bKkfehkvRCYo2IXIhJ0M9lM7eO4bkR9vRn68mV8ZP3bsPbsQor/oZbwQmbAjwW5mD5jZz83sRTPbsdp1ZnbWzH5qZk+Z2ek+nvdhM7tkZs/eMDZpZo+Z2Qvd77yy4fb68XkzO99dk6fM7EN98OOgmf2VmZ0xs+fM7I+7431dk8CPvq6JmQ2Y2d+Z2dNdP/5Dd3xz6+Huff0CUATwEoCjACoAngZwV7/96PpyFsDUDpz3NwHcA+DZG8b+E4CHuj8/BOA/7pAfnwfwr/q8HjMA7un+PArgFwDu6veaBH70dU3Q6W440v25DOAJAPdtdj124s5+L4AX3f1ld18D8E10ildmg7v/EMBba3T1vYAn8aPvuPusuz/Z/XkRwBkA+9HnNQn86CveYcuLvO5EsO8HcGPx8HPYgQXt4gD+0sx+YmYnd8iHN7iVCnh+2sye6b7M3/a3EzdiZofRqZ+wo0VN3+IH0Oc12Y4irzsR7KlaNTslCdzv7vcA+BcA/sjMfnOH/LiV+AqAY+j0CJgF8MV+ndjMRgB8B8Bn3J13hei/H31fE99EkVfGTgT7OQAHb/j9AIALO+AH3P1C9/slAN9D5y3GTrGhAp7bjbtf7F5obQBfRZ/WxMzK6ATY1939u93hvq9Jyo+dWpPuuedxk0VeGTsR7D8GcNzMjphZBcDvolO8sq+Y2bCZjb7xM4APAng2nrWt3BIFPN+4mLp8DH1YE+v0LPoagDPu/qUbTH1dE+ZHv9dk24q89muH8S27jR9CZ6fzJQD/bod8OIqOEvA0gOf66QeAb6DzcrCBziudTwHYjU4brRe63yd3yI//BuCnAJ7pXlwzffDjn6DzVu4ZAE91vz7U7zUJ/OjrmgB4L4C/757vWQD/vju+qfXQJ+iEyAR9gk6ITFCwC5EJCnYhMkHBLkQmKNiFyAQFuxCZoGAXIhMU7EJkwv8HGSFbXc9ipxUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# creates a data generator object that transforms images\n",
    "datagen = ImageDataGenerator(\n",
    "rotation_range=40,\n",
    "width_shift_range=0.2,\n",
    "height_shift_range=0.2,\n",
    "shear_range=0.2,\n",
    "zoom_range=0.2,\n",
    "horizontal_flip=True,\n",
    "fill_mode='nearest')\n",
    "\n",
    "# pick an image to transform\n",
    "test_img = train_images[20]\n",
    "img = image.img_to_array(test_img)  # convert image to numpy arry\n",
    "img = img.reshape((1,) + img.shape)  # reshape image\n",
    "\n",
    "i = 0\n",
    "\n",
    "for batch in datagen.flow(img, save_prefix='test', save_format='jpeg'):  # this loops runs forever until we break, saving images to current directory with specified prefix\n",
    "    plt.figure(i)\n",
    "    plot = plt.imshow(image.img_to_array(batch[0]))\n",
    "    i += 1\n",
    "    if i > 4:  # show 4 images\n",
    "        break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nc9RyHPYUnSK"
   },
   "source": [
    "### Pretrained Models\n",
    "You would have noticed that the model above takes a few minutes to train in the NoteBook and only gives an accuaracy of ~70%. This is okay but surely there is a way to improve on this. \n",
    "\n",
    "In this section we will talk about using a pretrained CNN as apart of our own custom network to improve the accuracy of our model. We know that CNN's alone (with no dense layers) don't do anything other than map the presence of features from our input. This means we can use a pretrained CNN, one trained on millions of images, as the start of our model. This will allow us to have a very good convolutional base before adding our own dense layered classifier at the end. In fact, by using this techique we can train a very good classifier for a realtively small dataset (< 10,000 images). This is because the convnet already has a very good idea of what features to look for in an image and can find them very effectively. So, if we can determine the presence of features all the rest of the model needs to do is determine which combination of features makes a specific image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u10oZO1oXT6Y"
   },
   "source": [
    "### Fine Tuning\n",
    "When we employ the technique defined above, we will often want to tweak the final layers in our convolutional base to work better for our specific problem. This involves not touching or retraining the earlier layers in our convolutional base but only adjusting the final few. We do this because the first layers in our base are very good at extracting low level features lile lines and edges, things that are similar for any kind of image. Where the later layers are better at picking up very specific features like shapes or even eyes. If we adjust the final layers than we can look for only features relevant to our very specific problem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XolyariNdj5p"
   },
   "source": [
    "## Using a Pretrained Model\n",
    "In this section we will combine the tecniques we learned above and use a pretrained model and fine tuning to classify images of dogs and cats using a small dataset.\n",
    "\n",
    "*This tutorial is based on the following guide from the TensorFlow documentation: https://www.tensorflow.org/tutorials/images/transfer_learning*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "2nRe9qWmgxm7"
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "keras = tf.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUx4I_4jg2Tc"
   },
   "source": [
    "### Dataset\n",
    "We will load the *cats_vs_dogs* dataset from the modoule tensorflow_datatsets.\n",
    "\n",
    "This dataset contains (image, label) pairs where images have different dimensions and 3 color channels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_datasets in c:\\users\\abhay\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (4.4.0)\n",
      "Requirement already satisfied: promise in c:\\users\\abhay\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: six in c:\\users\\abhay\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from tensorflow_datasets) (1.16.0)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in c:\\users\\abhay\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from tensorflow_datasets) (3.19.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\abhay\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from tensorflow_datasets) (1.21.4)\n",
      "Requirement already satisfied: termcolor in c:\\users\\abhay\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from tensorflow_datasets) (1.1.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\abhay\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from tensorflow_datasets) (0.12.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\abhay\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from tensorflow_datasets) (5.4.0)\n",
      "Requirement already satisfied: tensorflow-metadata in c:\\users\\abhay\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from tensorflow_datasets) (1.5.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\abhay\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from tensorflow_datasets) (4.0.1)\n",
      "Requirement already satisfied: dill in c:\\users\\abhay\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from tensorflow_datasets) (0.3.4)\n",
      "Requirement already satisfied: attrs>=18.1.0 in c:\\users\\abhay\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from tensorflow_datasets) (21.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\abhay\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from tensorflow_datasets) (2.26.0)\n",
      "Requirement already satisfied: future in c:\\users\\abhay\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from tensorflow_datasets) (0.18.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\abhay\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from tensorflow_datasets) (4.31.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\abhay\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (1.24.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abhay\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abhay\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\abhay\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.9)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\abhay\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from importlib-resources->tensorflow_datasets) (3.6.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in c:\\users\\abhay\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from tensorflow-metadata->tensorflow_datasets) (1.54.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "PuGu50NlgreO"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18436/2931300807.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtfds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtfds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable_progress_bar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# split the data manually into 80% training, 10% testing, 10% validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m (raw_train, raw_validation, raw_test), metadata = tfds.load(\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_datasets'"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "# split the data manually into 80% training, 10% testing, 10% validation\n",
    "(raw_train, raw_validation, raw_test), metadata = tfds.load(\n",
    "    'cats_vs_dogs',\n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Mk_MpiQyh-as"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metadata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18436/1586137866.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_label_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint2str\u001b[0m  \u001b[1;31m# creates a function object that we can use to get labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# display 2 images from the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'metadata' is not defined"
     ]
    }
   ],
   "source": [
    "get_label_name = metadata.features['label'].int2str  # creates a function object that we can use to get labels\n",
    "\n",
    "# display 2 images from the dataset\n",
    "for image, label in raw_train.take(5):\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    plt.title(get_label_name(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCdodmcYiPOF"
   },
   "source": [
    "### Data Preprocessing\n",
    "Since the sizes of our images are all different, we need to convert them all to the same size. We can create a function that will do that for us below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "tcoKn1VUieqx"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 160 # All images will be resized to 160x160\n",
    "\n",
    "def format_example(image, label):\n",
    "    \"\"\"\n",
    "    returns an image that is reshaped to IMG_SIZE\n",
    "    \"\"\"\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image/127.5) - 1\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwIB21lailXh"
   },
   "source": [
    "Now we can apply this function to all our images using ```.map()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "0E8iqYOAipdU"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18436/4129722716.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraw_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat_example\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mvalidation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraw_validation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat_example\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraw_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat_example\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'raw_train' is not defined"
     ]
    }
   ],
   "source": [
    "train = raw_train.map(format_example)\n",
    "validation = raw_validation.map(format_example)\n",
    "test = raw_test.map(format_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QORLTVNaiqym"
   },
   "source": [
    "Let's have a look at our images now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "dU5JIa2Jiv9U"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18436/3154354068.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_label_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "for image, label in train.take(2):\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    plt.title(get_label_name(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFnFVaNQi7Vq"
   },
   "source": [
    "Finally we will shuffle and batch the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "v5ZIhkFPi_Pb"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18436/544093959.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mSHUFFLE_BUFFER_SIZE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSHUFFLE_BUFFER_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mvalidation_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtest_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "\n",
    "train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "validation_batches = validation.batch(BATCH_SIZE)\n",
    "test_batches = test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QxI-fOAjDzC"
   },
   "source": [
    "Now if we look at the shape of an original image vs the new image we will see it has been changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "zyqrCYNOjY9v"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18436/1781463578.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Original shape:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"New shape:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'raw_train' is not defined"
     ]
    }
   ],
   "source": [
    "for img, label in raw_train.take(2):\n",
    "    print(\"Original shape:\", img.shape)\n",
    "\n",
    "for img, label in train.take(2):\n",
    "    print(\"New shape:\", img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NMpKJ3Xbj4BW"
   },
   "source": [
    "### Picking a Pretrained Model\n",
    "The model we are going to use as the convolutional base for our model is the **MobileNet V2** developed at Google. This model is trained on 1.4 million images and has 1000 different classes.\n",
    "\n",
    "We want to use this model but only its convolutional base. So, when we load in the model, we'll specify that we don't want to load the top (classification) layer. We'll tell the model what input shape to expect and to use the predetermined weights from *imagenet* (Googles dataset).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "2a09os6dkokI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5\n",
      "9412608/9406464 [==============================] - 4s 0us/step\n",
      "9420800/9406464 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "# include_top parameter is set to false, because we don't want 1000 different classs, we only want dogs and cats\n",
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "uRvMuWoFR2CO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenetv2_1.00_160\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 160, 160, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 80, 80, 32)   864         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalization)  (None, 80, 80, 32)   128         ['Conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)              (None, 80, 80, 32)   0           ['bn_Conv1[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (Depth  (None, 80, 80, 32)  288         ['Conv1_relu[0][0]']             \n",
      " wiseConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN (Ba  (None, 80, 80, 32)  128         ['expanded_conv_depthwise[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_relu (  (None, 80, 80, 32)  0           ['expanded_conv_depthwise_BN[0][0\n",
      " ReLU)                                                           ]']                              \n",
      "                                                                                                  \n",
      " expanded_conv_project (Conv2D)  (None, 80, 80, 16)  512         ['expanded_conv_depthwise_relu[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (Batc  (None, 80, 80, 16)  64          ['expanded_conv_project[0][0]']  \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)        (None, 80, 80, 96)   1536        ['expanded_conv_project_BN[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNormal  (None, 80, 80, 96)  384         ['block_1_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)     (None, 80, 80, 96)   0           ['block_1_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D)    (None, 81, 81, 96)   0           ['block_1_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_1_depthwise (DepthwiseCo  (None, 40, 40, 96)  864         ['block_1_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (BatchNor  (None, 40, 40, 96)  384         ['block_1_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (ReLU)  (None, 40, 40, 96)   0           ['block_1_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)       (None, 40, 40, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchNorma  (None, 40, 40, 24)  96          ['block_1_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)        (None, 40, 40, 144)  3456        ['block_1_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNormal  (None, 40, 40, 144)  576        ['block_2_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)     (None, 40, 40, 144)  0           ['block_2_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_2_depthwise (DepthwiseCo  (None, 40, 40, 144)  1296       ['block_2_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (BatchNor  (None, 40, 40, 144)  576        ['block_2_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (ReLU)  (None, 40, 40, 144)  0           ['block_2_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)       (None, 40, 40, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchNorma  (None, 40, 40, 24)  96          ['block_2_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_add (Add)              (None, 40, 40, 24)   0           ['block_1_project_BN[0][0]',     \n",
      "                                                                  'block_2_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)        (None, 40, 40, 144)  3456        ['block_2_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNormal  (None, 40, 40, 144)  576        ['block_3_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)     (None, 40, 40, 144)  0           ['block_3_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D)    (None, 41, 41, 144)  0           ['block_3_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_3_depthwise (DepthwiseCo  (None, 20, 20, 144)  1296       ['block_3_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (BatchNor  (None, 20, 20, 144)  576        ['block_3_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (ReLU)  (None, 20, 20, 144)  0           ['block_3_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)       (None, 20, 20, 32)   4608        ['block_3_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchNorma  (None, 20, 20, 32)  128         ['block_3_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)        (None, 20, 20, 192)  6144        ['block_3_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNormal  (None, 20, 20, 192)  768        ['block_4_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)     (None, 20, 20, 192)  0           ['block_4_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_4_depthwise (DepthwiseCo  (None, 20, 20, 192)  1728       ['block_4_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (BatchNor  (None, 20, 20, 192)  768        ['block_4_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (ReLU)  (None, 20, 20, 192)  0           ['block_4_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)       (None, 20, 20, 32)   6144        ['block_4_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchNorma  (None, 20, 20, 32)  128         ['block_4_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_add (Add)              (None, 20, 20, 32)   0           ['block_3_project_BN[0][0]',     \n",
      "                                                                  'block_4_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)        (None, 20, 20, 192)  6144        ['block_4_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNormal  (None, 20, 20, 192)  768        ['block_5_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)     (None, 20, 20, 192)  0           ['block_5_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_5_depthwise (DepthwiseCo  (None, 20, 20, 192)  1728       ['block_5_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (BatchNor  (None, 20, 20, 192)  768        ['block_5_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (ReLU)  (None, 20, 20, 192)  0           ['block_5_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)       (None, 20, 20, 32)   6144        ['block_5_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchNorma  (None, 20, 20, 32)  128         ['block_5_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_add (Add)              (None, 20, 20, 32)   0           ['block_4_add[0][0]',            \n",
      "                                                                  'block_5_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)        (None, 20, 20, 192)  6144        ['block_5_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNormal  (None, 20, 20, 192)  768        ['block_6_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)     (None, 20, 20, 192)  0           ['block_6_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D)    (None, 21, 21, 192)  0           ['block_6_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_6_depthwise (DepthwiseCo  (None, 10, 10, 192)  1728       ['block_6_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (BatchNor  (None, 10, 10, 192)  768        ['block_6_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (ReLU)  (None, 10, 10, 192)  0           ['block_6_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)       (None, 10, 10, 64)   12288       ['block_6_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchNorma  (None, 10, 10, 64)  256         ['block_6_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)        (None, 10, 10, 384)  24576       ['block_6_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNormal  (None, 10, 10, 384)  1536       ['block_7_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)     (None, 10, 10, 384)  0           ['block_7_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_7_depthwise (DepthwiseCo  (None, 10, 10, 384)  3456       ['block_7_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (BatchNor  (None, 10, 10, 384)  1536       ['block_7_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (ReLU)  (None, 10, 10, 384)  0           ['block_7_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)       (None, 10, 10, 64)   24576       ['block_7_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchNorma  (None, 10, 10, 64)  256         ['block_7_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_add (Add)              (None, 10, 10, 64)   0           ['block_6_project_BN[0][0]',     \n",
      "                                                                  'block_7_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)        (None, 10, 10, 384)  24576       ['block_7_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNormal  (None, 10, 10, 384)  1536       ['block_8_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)     (None, 10, 10, 384)  0           ['block_8_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_8_depthwise (DepthwiseCo  (None, 10, 10, 384)  3456       ['block_8_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (BatchNor  (None, 10, 10, 384)  1536       ['block_8_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (ReLU)  (None, 10, 10, 384)  0           ['block_8_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)       (None, 10, 10, 64)   24576       ['block_8_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchNorma  (None, 10, 10, 64)  256         ['block_8_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_add (Add)              (None, 10, 10, 64)   0           ['block_7_add[0][0]',            \n",
      "                                                                  'block_8_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)        (None, 10, 10, 384)  24576       ['block_8_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNormal  (None, 10, 10, 384)  1536       ['block_9_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)     (None, 10, 10, 384)  0           ['block_9_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_9_depthwise (DepthwiseCo  (None, 10, 10, 384)  3456       ['block_9_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (BatchNor  (None, 10, 10, 384)  1536       ['block_9_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (ReLU)  (None, 10, 10, 384)  0           ['block_9_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)       (None, 10, 10, 64)   24576       ['block_9_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchNorma  (None, 10, 10, 64)  256         ['block_9_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_add (Add)              (None, 10, 10, 64)   0           ['block_8_add[0][0]',            \n",
      "                                                                  'block_9_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)       (None, 10, 10, 384)  24576       ['block_9_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchNorma  (None, 10, 10, 384)  1536       ['block_10_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU)    (None, 10, 10, 384)  0           ['block_10_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_depthwise (DepthwiseC  (None, 10, 10, 384)  3456       ['block_10_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " block_10_depthwise_BN (BatchNo  (None, 10, 10, 384)  1536       ['block_10_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (ReLU)  (None, 10, 10, 384)  0          ['block_10_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)      (None, 10, 10, 96)   36864       ['block_10_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_10_project_BN (BatchNorm  (None, 10, 10, 96)  384         ['block_10_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)       (None, 10, 10, 576)  55296       ['block_10_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchNorma  (None, 10, 10, 576)  2304       ['block_11_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU)    (None, 10, 10, 576)  0           ['block_11_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_11_depthwise (DepthwiseC  (None, 10, 10, 576)  5184       ['block_11_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (BatchNo  (None, 10, 10, 576)  2304       ['block_11_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (ReLU)  (None, 10, 10, 576)  0          ['block_11_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)      (None, 10, 10, 96)   55296       ['block_11_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_11_project_BN (BatchNorm  (None, 10, 10, 96)  384         ['block_11_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_add (Add)             (None, 10, 10, 96)   0           ['block_10_project_BN[0][0]',    \n",
      "                                                                  'block_11_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)       (None, 10, 10, 576)  55296       ['block_11_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchNorma  (None, 10, 10, 576)  2304       ['block_12_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU)    (None, 10, 10, 576)  0           ['block_12_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_12_depthwise (DepthwiseC  (None, 10, 10, 576)  5184       ['block_12_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (BatchNo  (None, 10, 10, 576)  2304       ['block_12_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (ReLU)  (None, 10, 10, 576)  0          ['block_12_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)      (None, 10, 10, 96)   55296       ['block_12_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_12_project_BN (BatchNorm  (None, 10, 10, 96)  384         ['block_12_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_add (Add)             (None, 10, 10, 96)   0           ['block_11_add[0][0]',           \n",
      "                                                                  'block_12_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)       (None, 10, 10, 576)  55296       ['block_12_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchNorma  (None, 10, 10, 576)  2304       ['block_13_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU)    (None, 10, 10, 576)  0           ['block_13_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2D)   (None, 11, 11, 576)  0           ['block_13_expand_relu[0][0]']   \n",
      "                                                                                                  \n",
      " block_13_depthwise (DepthwiseC  (None, 5, 5, 576)   5184        ['block_13_pad[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (BatchNo  (None, 5, 5, 576)   2304        ['block_13_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (ReLU)  (None, 5, 5, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)      (None, 5, 5, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_13_project_BN (BatchNorm  (None, 5, 5, 160)   640         ['block_13_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)       (None, 5, 5, 960)    153600      ['block_13_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchNorma  (None, 5, 5, 960)   3840        ['block_14_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU)    (None, 5, 5, 960)    0           ['block_14_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_14_depthwise (DepthwiseC  (None, 5, 5, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (BatchNo  (None, 5, 5, 960)   3840        ['block_14_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (ReLU)  (None, 5, 5, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)      (None, 5, 5, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_14_project_BN (BatchNorm  (None, 5, 5, 160)   640         ['block_14_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_add (Add)             (None, 5, 5, 160)    0           ['block_13_project_BN[0][0]',    \n",
      "                                                                  'block_14_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)       (None, 5, 5, 960)    153600      ['block_14_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchNorma  (None, 5, 5, 960)   3840        ['block_15_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU)    (None, 5, 5, 960)    0           ['block_15_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_15_depthwise (DepthwiseC  (None, 5, 5, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (BatchNo  (None, 5, 5, 960)   3840        ['block_15_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (ReLU)  (None, 5, 5, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)      (None, 5, 5, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_15_project_BN (BatchNorm  (None, 5, 5, 160)   640         ['block_15_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_add (Add)             (None, 5, 5, 160)    0           ['block_14_add[0][0]',           \n",
      "                                                                  'block_15_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)       (None, 5, 5, 960)    153600      ['block_15_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchNorma  (None, 5, 5, 960)   3840        ['block_16_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU)    (None, 5, 5, 960)    0           ['block_16_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_16_depthwise (DepthwiseC  (None, 5, 5, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (BatchNo  (None, 5, 5, 960)   3840        ['block_16_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (ReLU)  (None, 5, 5, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)      (None, 5, 5, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_16_project_BN (BatchNorm  (None, 5, 5, 320)   1280        ['block_16_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 5, 5, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalization)  (None, 5, 5, 1280)  5120        ['Conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " out_relu (ReLU)                (None, 5, 5, 1280)   0           ['Conv_1_bn[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,257,984\n",
      "Trainable params: 2,223,872\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckYqfl7Vky3S"
   },
   "source": [
    "At this point this *base_model* will simply output a shape (32, 5, 5, 1280) tensor that is a feature extraction from our original (1, 160, 160, 3) image. The 32 means that we have 32 layers of differnt filters/features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "yojo6ONzlFGF"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_batches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18436/686218324.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_batches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfeature_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_batches' is not defined"
     ]
    }
   ],
   "source": [
    "for image, _ in train_batches.take(1):\n",
    "    pass\n",
    "\n",
    "feature_batch = base_model(image)\n",
    "print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQ2kn1P_lhsg"
   },
   "source": [
    "### Freezing the Base\n",
    "The term **freezing** refers to disabling the training property of a layer. It simply means we won’t make any changes to the weights of any layers that are frozen during training. This is important as we don't want to change the convolutional base that already has learned weights.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "6hXctqtYl8o5"
   },
   "outputs": [],
   "source": [
    "# this will stop from training the base model\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "1jIGFXOrl9wc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenetv2_1.00_160\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 160, 160, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 80, 80, 32)   864         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalization)  (None, 80, 80, 32)   128         ['Conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)              (None, 80, 80, 32)   0           ['bn_Conv1[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (Depth  (None, 80, 80, 32)  288         ['Conv1_relu[0][0]']             \n",
      " wiseConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN (Ba  (None, 80, 80, 32)  128         ['expanded_conv_depthwise[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_relu (  (None, 80, 80, 32)  0           ['expanded_conv_depthwise_BN[0][0\n",
      " ReLU)                                                           ]']                              \n",
      "                                                                                                  \n",
      " expanded_conv_project (Conv2D)  (None, 80, 80, 16)  512         ['expanded_conv_depthwise_relu[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (Batc  (None, 80, 80, 16)  64          ['expanded_conv_project[0][0]']  \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)        (None, 80, 80, 96)   1536        ['expanded_conv_project_BN[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNormal  (None, 80, 80, 96)  384         ['block_1_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)     (None, 80, 80, 96)   0           ['block_1_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D)    (None, 81, 81, 96)   0           ['block_1_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_1_depthwise (DepthwiseCo  (None, 40, 40, 96)  864         ['block_1_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (BatchNor  (None, 40, 40, 96)  384         ['block_1_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (ReLU)  (None, 40, 40, 96)   0           ['block_1_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)       (None, 40, 40, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchNorma  (None, 40, 40, 24)  96          ['block_1_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)        (None, 40, 40, 144)  3456        ['block_1_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNormal  (None, 40, 40, 144)  576        ['block_2_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)     (None, 40, 40, 144)  0           ['block_2_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_2_depthwise (DepthwiseCo  (None, 40, 40, 144)  1296       ['block_2_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (BatchNor  (None, 40, 40, 144)  576        ['block_2_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (ReLU)  (None, 40, 40, 144)  0           ['block_2_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)       (None, 40, 40, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchNorma  (None, 40, 40, 24)  96          ['block_2_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_add (Add)              (None, 40, 40, 24)   0           ['block_1_project_BN[0][0]',     \n",
      "                                                                  'block_2_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)        (None, 40, 40, 144)  3456        ['block_2_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNormal  (None, 40, 40, 144)  576        ['block_3_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)     (None, 40, 40, 144)  0           ['block_3_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D)    (None, 41, 41, 144)  0           ['block_3_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_3_depthwise (DepthwiseCo  (None, 20, 20, 144)  1296       ['block_3_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (BatchNor  (None, 20, 20, 144)  576        ['block_3_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (ReLU)  (None, 20, 20, 144)  0           ['block_3_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)       (None, 20, 20, 32)   4608        ['block_3_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchNorma  (None, 20, 20, 32)  128         ['block_3_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)        (None, 20, 20, 192)  6144        ['block_3_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNormal  (None, 20, 20, 192)  768        ['block_4_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)     (None, 20, 20, 192)  0           ['block_4_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_4_depthwise (DepthwiseCo  (None, 20, 20, 192)  1728       ['block_4_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (BatchNor  (None, 20, 20, 192)  768        ['block_4_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (ReLU)  (None, 20, 20, 192)  0           ['block_4_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)       (None, 20, 20, 32)   6144        ['block_4_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchNorma  (None, 20, 20, 32)  128         ['block_4_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_add (Add)              (None, 20, 20, 32)   0           ['block_3_project_BN[0][0]',     \n",
      "                                                                  'block_4_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)        (None, 20, 20, 192)  6144        ['block_4_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNormal  (None, 20, 20, 192)  768        ['block_5_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)     (None, 20, 20, 192)  0           ['block_5_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_5_depthwise (DepthwiseCo  (None, 20, 20, 192)  1728       ['block_5_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (BatchNor  (None, 20, 20, 192)  768        ['block_5_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (ReLU)  (None, 20, 20, 192)  0           ['block_5_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)       (None, 20, 20, 32)   6144        ['block_5_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchNorma  (None, 20, 20, 32)  128         ['block_5_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_add (Add)              (None, 20, 20, 32)   0           ['block_4_add[0][0]',            \n",
      "                                                                  'block_5_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)        (None, 20, 20, 192)  6144        ['block_5_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNormal  (None, 20, 20, 192)  768        ['block_6_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)     (None, 20, 20, 192)  0           ['block_6_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D)    (None, 21, 21, 192)  0           ['block_6_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_6_depthwise (DepthwiseCo  (None, 10, 10, 192)  1728       ['block_6_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (BatchNor  (None, 10, 10, 192)  768        ['block_6_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (ReLU)  (None, 10, 10, 192)  0           ['block_6_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)       (None, 10, 10, 64)   12288       ['block_6_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchNorma  (None, 10, 10, 64)  256         ['block_6_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)        (None, 10, 10, 384)  24576       ['block_6_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNormal  (None, 10, 10, 384)  1536       ['block_7_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)     (None, 10, 10, 384)  0           ['block_7_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_7_depthwise (DepthwiseCo  (None, 10, 10, 384)  3456       ['block_7_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (BatchNor  (None, 10, 10, 384)  1536       ['block_7_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (ReLU)  (None, 10, 10, 384)  0           ['block_7_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)       (None, 10, 10, 64)   24576       ['block_7_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchNorma  (None, 10, 10, 64)  256         ['block_7_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_add (Add)              (None, 10, 10, 64)   0           ['block_6_project_BN[0][0]',     \n",
      "                                                                  'block_7_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)        (None, 10, 10, 384)  24576       ['block_7_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNormal  (None, 10, 10, 384)  1536       ['block_8_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)     (None, 10, 10, 384)  0           ['block_8_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_8_depthwise (DepthwiseCo  (None, 10, 10, 384)  3456       ['block_8_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (BatchNor  (None, 10, 10, 384)  1536       ['block_8_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (ReLU)  (None, 10, 10, 384)  0           ['block_8_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)       (None, 10, 10, 64)   24576       ['block_8_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchNorma  (None, 10, 10, 64)  256         ['block_8_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_add (Add)              (None, 10, 10, 64)   0           ['block_7_add[0][0]',            \n",
      "                                                                  'block_8_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)        (None, 10, 10, 384)  24576       ['block_8_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNormal  (None, 10, 10, 384)  1536       ['block_9_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)     (None, 10, 10, 384)  0           ['block_9_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_9_depthwise (DepthwiseCo  (None, 10, 10, 384)  3456       ['block_9_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (BatchNor  (None, 10, 10, 384)  1536       ['block_9_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (ReLU)  (None, 10, 10, 384)  0           ['block_9_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)       (None, 10, 10, 64)   24576       ['block_9_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchNorma  (None, 10, 10, 64)  256         ['block_9_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_add (Add)              (None, 10, 10, 64)   0           ['block_8_add[0][0]',            \n",
      "                                                                  'block_9_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)       (None, 10, 10, 384)  24576       ['block_9_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchNorma  (None, 10, 10, 384)  1536       ['block_10_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU)    (None, 10, 10, 384)  0           ['block_10_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_depthwise (DepthwiseC  (None, 10, 10, 384)  3456       ['block_10_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (BatchNo  (None, 10, 10, 384)  1536       ['block_10_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (ReLU)  (None, 10, 10, 384)  0          ['block_10_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)      (None, 10, 10, 96)   36864       ['block_10_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_10_project_BN (BatchNorm  (None, 10, 10, 96)  384         ['block_10_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)       (None, 10, 10, 576)  55296       ['block_10_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchNorma  (None, 10, 10, 576)  2304       ['block_11_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU)    (None, 10, 10, 576)  0           ['block_11_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_11_depthwise (DepthwiseC  (None, 10, 10, 576)  5184       ['block_11_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (BatchNo  (None, 10, 10, 576)  2304       ['block_11_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (ReLU)  (None, 10, 10, 576)  0          ['block_11_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)      (None, 10, 10, 96)   55296       ['block_11_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_11_project_BN (BatchNorm  (None, 10, 10, 96)  384         ['block_11_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_add (Add)             (None, 10, 10, 96)   0           ['block_10_project_BN[0][0]',    \n",
      "                                                                  'block_11_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)       (None, 10, 10, 576)  55296       ['block_11_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchNorma  (None, 10, 10, 576)  2304       ['block_12_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU)    (None, 10, 10, 576)  0           ['block_12_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_12_depthwise (DepthwiseC  (None, 10, 10, 576)  5184       ['block_12_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (BatchNo  (None, 10, 10, 576)  2304       ['block_12_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (ReLU)  (None, 10, 10, 576)  0          ['block_12_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)      (None, 10, 10, 96)   55296       ['block_12_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_12_project_BN (BatchNorm  (None, 10, 10, 96)  384         ['block_12_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_add (Add)             (None, 10, 10, 96)   0           ['block_11_add[0][0]',           \n",
      "                                                                  'block_12_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)       (None, 10, 10, 576)  55296       ['block_12_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchNorma  (None, 10, 10, 576)  2304       ['block_13_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU)    (None, 10, 10, 576)  0           ['block_13_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2D)   (None, 11, 11, 576)  0           ['block_13_expand_relu[0][0]']   \n",
      "                                                                                                  \n",
      " block_13_depthwise (DepthwiseC  (None, 5, 5, 576)   5184        ['block_13_pad[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (BatchNo  (None, 5, 5, 576)   2304        ['block_13_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (ReLU)  (None, 5, 5, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)      (None, 5, 5, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_13_project_BN (BatchNorm  (None, 5, 5, 160)   640         ['block_13_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)       (None, 5, 5, 960)    153600      ['block_13_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchNorma  (None, 5, 5, 960)   3840        ['block_14_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU)    (None, 5, 5, 960)    0           ['block_14_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_14_depthwise (DepthwiseC  (None, 5, 5, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (BatchNo  (None, 5, 5, 960)   3840        ['block_14_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (ReLU)  (None, 5, 5, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)      (None, 5, 5, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_14_project_BN (BatchNorm  (None, 5, 5, 160)   640         ['block_14_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_add (Add)             (None, 5, 5, 160)    0           ['block_13_project_BN[0][0]',    \n",
      "                                                                  'block_14_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)       (None, 5, 5, 960)    153600      ['block_14_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchNorma  (None, 5, 5, 960)   3840        ['block_15_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU)    (None, 5, 5, 960)    0           ['block_15_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_15_depthwise (DepthwiseC  (None, 5, 5, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (BatchNo  (None, 5, 5, 960)   3840        ['block_15_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (ReLU)  (None, 5, 5, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)      (None, 5, 5, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_15_project_BN (BatchNorm  (None, 5, 5, 160)   640         ['block_15_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_add (Add)             (None, 5, 5, 160)    0           ['block_14_add[0][0]',           \n",
      "                                                                  'block_15_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)       (None, 5, 5, 960)    153600      ['block_15_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchNorma  (None, 5, 5, 960)   3840        ['block_16_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU)    (None, 5, 5, 960)    0           ['block_16_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_16_depthwise (DepthwiseC  (None, 5, 5, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (BatchNo  (None, 5, 5, 960)   3840        ['block_16_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (ReLU)  (None, 5, 5, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)      (None, 5, 5, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_16_project_BN (BatchNorm  (None, 5, 5, 320)   1280        ['block_16_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 5, 5, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalization)  (None, 5, 5, 1280)  5120        ['Conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " out_relu (ReLU)                (None, 5, 5, 1280)   0           ['Conv_1_bn[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,257,984\n",
      "Trainable params: 0\n",
      "Non-trainable params: 2,257,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7UJLbJ7mJzw"
   },
   "source": [
    "### Adding our Classifier\n",
    "Now that we have our base layer setup, we can add the classifier. Instead of flattening the feature map of the base layer we will use a global average pooling layer that will average the entire 5x5 area of each 2D feature map and return to us a single 1280 element vector per filter.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "3uUwG5wrnFD6"
   },
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejxd7rjInIRp"
   },
   "source": [
    "Finally, we will add the predicition layer that will be a single dense neuron. We can do this because we only have two classes to predict for.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "GA-iVZj9nH_N"
   },
   "outputs": [],
   "source": [
    "prediction_layer = keras.layers.Dense(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dn9G9KiFnXu6"
   },
   "source": [
    "Now we will combine these layers together in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "E_IJucQNnXBK"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  global_average_layer,\n",
    "  prediction_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "fLYdAL2uSt_a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_160 (Funct  (None, 5, 5, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 1,281\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHepCsPXnpYZ"
   },
   "source": [
    "### Training the Model\n",
    "Now we will train and compile the model. We will use a very small learning rate to ensure that the model does not have any major changes made to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "GQhg2WxHnxra"
   },
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "# binary for 2 classes, because we only need 2 classes\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "8Fx9nySdoZuL"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'validation_batches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18436/991623561.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mloss0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'validation_batches' is not defined"
     ]
    }
   ],
   "source": [
    "# We can evaluate the model right now to see how it does before training it on our new images\n",
    "initial_epochs = 3\n",
    "validation_steps=20\n",
    "\n",
    "loss0,accuracy0 = model.evaluate(validation_batches, steps = validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "edMXObctojl6"
   },
   "outputs": [],
   "source": [
    "# Now we can train it on our images\n",
    "history = model.fit(train_batches,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=validation_batches)\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VUUt3AxA2lf2"
   },
   "outputs": [],
   "source": [
    "model.save(\"dogs_vs_cats.h5\")  # we can save the model and reload it at anytime in the future\n",
    "new_model = tf.keras.models.load_model('dogs_vs_cats.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2095EQ4Y3qJk"
   },
   "source": [
    "And that's it for this section on computer vision!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8YcdmWUvYae"
   },
   "source": [
    "## Object Detection\n",
    "If you'd like to learn how you can perform object detection and recognition with tensorflow check out the guide below.\n",
    "\n",
    "https://github.com/tensorflow/models/tree/master/research/object_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oEiX-D2f2tvI"
   },
   "source": [
    "## Sources\n",
    "1. “Convolutional Neural Network (CNN) &nbsp;: &nbsp; TensorFlow Core.” TensorFlow, www.tensorflow.org/tutorials/images/cnn.\n",
    "2. “Transfer Learning with a Pretrained ConvNet &nbsp;: &nbsp; TensorFlow Core.” TensorFlow, www.tensorflow.org/tutorials/images/transfer_learning.\n",
    "3. Chollet François. Deep Learning with Python. Manning Publications Co., 2018.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Computer Vision.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
